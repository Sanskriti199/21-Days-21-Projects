{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Project 7: Feature Engineering for Customer Churn Prediction\n",
        "\n",
        "Project Objective: To demonstrate the power of feature engineering by building and comparing two models: a baseline model with raw features and an enhanced model with newly engineered features. The goal is to accurately predict customer churn for a telecommunications company."
      ],
      "metadata": {
        "id": "4NwQHLqCbpAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Setup - Importing Libraries and Loading Data"
      ],
      "metadata": {
        "id": "yqwIrW8hbx5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "sns.set_style('whitegrid')"
      ],
      "metadata": {
        "id": "GLRy9awvb1F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/HarshvardhanSingh-13/Datasets\""
      ],
      "metadata": {
        "id": "6k1ou19icAD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Datasets/Customer Churn Dataset/Telco-Customer-Churn.csv')\n",
        "\n",
        "print(\"Dataset loaded successfully.\")\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lA92RiwMcLnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Data Cleaning and Initial Preparation"
      ],
      "metadata": {
        "id": "gKM9PBL-cg4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "WaeQCnrSchfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape before cleaning: {df.shape}\")\n",
        "\n",
        "# Convert TotalCharges to numeric, coercing errors to NaN\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "print(f\"Shape after converting TotalCharges to numeric: {df.shape}\")\n",
        "\n",
        "\n",
        "# Find how many rows have missing TotalCharges\n",
        "print(f\"Number of missing TotalCharges: {df['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# Impute the missing values with the median\n",
        "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
        "print(f\"Shape after imputing TotalCharges: {df.shape}\")\n",
        "\n",
        "\n",
        "# Convert target variable 'Churn' to binary\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "print(f\"Shape after converting Churn to binary: {df.shape}\")\n",
        "\n",
        "\n",
        "# Drop rows with missing Churn values\n",
        "df.dropna(subset=['Churn'], inplace=True)\n",
        "print(f\"Shape after dropping rows with missing Churn: {df.shape}\")\n",
        "\n",
        "\n",
        "# Drop customerID as it's not a predictive feature\n",
        "# df.drop('customerID', axis=1, inplace=True) # This line is commented out as customerID is already dropped\n",
        "\n",
        "print(\"\\nData cleaning complete.\")"
      ],
      "metadata": {
        "id": "XYXOOiG7cmYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "VbVfAFVIcytr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Churn'].value_counts()"
      ],
      "metadata": {
        "id": "SatiT8xhc1Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Model 1 - Baseline Performance (Without Feature Engineering)"
      ],
      "metadata": {
        "id": "yaPy1BbMc5l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target (y)\n",
        "X_base = df.drop('Churn', axis=1)\n",
        "y_base = df['Churn']\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "numerical_features_base = X_base.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features_base = X_base.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Create the preprocessing pipeline\n",
        "preprocessor_base = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_base),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_base)])\n",
        "\n",
        "# Split data\n",
        "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.2, random_state=42, stratify=y_base)\n",
        "\n",
        "# Create the full pipeline with a classifier\n",
        "baseline_model = Pipeline(steps=[('preprocessor', preprocessor_base),\n",
        "                                 ('classifier', LogisticRegression(random_state=42, max_iter=1000))])\n",
        "\n",
        "# Train and evaluate the baseline model\n",
        "baseline_model.fit(X_train_base, y_train_base)\n",
        "y_pred_base = baseline_model.predict(X_test_base)\n",
        "\n",
        "print(\"--- Baseline Model Performance ---\")\n",
        "print(classification_report(y_test_base, y_pred_base))"
      ],
      "metadata": {
        "id": "fM1TPq21c7BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: The Core Task - Feature Engineering"
      ],
      "metadata": {
        "id": "33Tk-JqDdAVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tenure'].describe()"
      ],
      "metadata": {
        "id": "XZuNcsvLdBsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eng = df.copy()\n",
        "\n",
        "# 1. Binning 'tenure'\n",
        "bins = [0, 12, 24, 48, 60, 72]\n",
        "labels = ['0-1 Year', '1-2 Years', '2-4 Years', '4-5 Years', '5+ Years']\n",
        "df_eng['tenure_group'] = pd.cut(df_eng['tenure'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# 2. Simplifying categorical features\n",
        "df_eng['MultipleLines'] = df_eng['MultipleLines'].replace({'No phone service': 'No'})\n",
        "for col in ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']:\n",
        "    df_eng[col] = df_eng[col].replace({'No internet service': 'No'})\n",
        "\n",
        "# 3. Creating interaction/combination features\n",
        "df_eng['num_add_services'] = (df_eng[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']] == 'Yes').sum(axis=1)\n",
        "\n",
        "# 4. Create a feature for monthly charge to tenure ratio\n",
        "df_eng['monthly_charge_ratio'] = df_eng['MonthlyCharges'] / (df_eng['tenure'] + 1) # +1 to avoid division by zero\n",
        "\n",
        "print(\"Feature engineering complete. New features added.\")\n",
        "df_eng.head()"
      ],
      "metadata": {
        "id": "DRb92mJndGfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Model 2 - Performance with Engineered Features"
      ],
      "metadata": {
        "id": "6IVFYy9DdJ1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop original tenure as we have a binned version now\n",
        "df_eng.drop('tenure', axis=1, inplace=True)\n",
        "\n",
        "# Define features (X) and target (y) for the engineered dataset\n",
        "X_eng = df_eng.drop('Churn', axis=1)\n",
        "y_eng = df_eng['Churn']\n",
        "\n",
        "# Identify new feature types\n",
        "numerical_features_eng = X_eng.select_dtypes(include=np.number).columns.tolist()\n",
        "# Note: 'tenure_group' is now a categorical feature\n",
        "categorical_features_eng = X_eng.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Create the new preprocessing pipeline\n",
        "preprocessor_eng = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_eng),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_eng)])\n",
        "\n",
        "# Split data\n",
        "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(X_eng, y_eng, test_size=0.2, random_state=42, stratify=y_eng)\n",
        "\n",
        "# Create the full pipeline with the same classifier for a fair comparison\n",
        "enhanced_model = Pipeline(steps=[('preprocessor', preprocessor_eng),\n",
        "                                 ('classifier', LogisticRegression(random_state=42, max_iter=1000))])\n",
        "\n",
        "# Train and evaluate the enhanced model\n",
        "enhanced_model.fit(X_train_eng, y_train_eng)\n",
        "y_pred_eng = enhanced_model.predict(X_test_eng)\n",
        "\n",
        "print(\"--- Enhanced Model Performance (with Feature Engineering) ---\")\n",
        "print(classification_report(y_test_eng, y_pred_eng))"
      ],
      "metadata": {
        "id": "Qb-6B8I9dKpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Comparison and Final Conclusion"
      ],
      "metadata": {
        "id": "OI_GU87rdQ1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor_eng),\n",
        "                               ('classifier', RandomForestClassifier(random_state=42))])\n",
        "rf_pipeline.fit(X_train_eng, y_train_eng)\n",
        "\n",
        "# Extract feature names after one-hot encoding\n",
        "feature_names = rf_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "importances = rf_pipeline.named_steps['classifier'].feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='rocket', hue='Feature', legend=False)\n",
        "plt.title('Top 15 Most Important Features (from Enhanced Model)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yUwVMk-7dUQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform feature selection"
      ],
      "metadata": {
        "id": "Q2YXFrdwdZfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate a RandomForestClassifier to use as the base estimator for feature selection\n",
        "rf_selector = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate SelectFromModel\n",
        "# Using 'median' as the threshold means features with importance greater than the median importance will be selected.\n",
        "selector = SelectFromModel(estimator=rf_selector, threshold='median', prefit=False)\n",
        "\n",
        "# Create a pipeline for feature selection\n",
        "feature_selection_pipeline = Pipeline(steps=[('preprocessor', preprocessor_eng),\n",
        "                                             ('selector', selector)])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "feature_selection_pipeline.fit(X_train_eng, y_train_eng)\n",
        "\n",
        "# Transform the training and testing data to get the selected features\n",
        "X_train_selected = feature_selection_pipeline.transform(X_train_eng)\n",
        "X_test_selected = feature_selection_pipeline.transform(X_test_eng)\n",
        "\n",
        "# Print the shapes to compare\n",
        "print(f\"Original training data shape: {X_train_eng.shape}\")\n",
        "print(f\"Selected training data shape: {X_train_selected.shape}\")"
      ],
      "metadata": {
        "id": "3-MU5cGUdaPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model with selected features"
      ],
      "metadata": {
        "id": "Mge15R7seIyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_model = Pipeline(steps=[('preprocessor', preprocessor_eng),\n",
        "                                         ('classifier', LogisticRegression(random_state=42, max_iter=1000))])\n",
        "\n",
        "# Train the model using the selected features\n",
        "selected_features_model.fit(X_train_eng, y_train_eng)"
      ],
      "metadata": {
        "id": "HwCYGCP3eJUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_selected = selected_features_model.predict(X_test_eng)\n",
        "\n",
        "print(\"--- Model Performance (with Selected Features) ---\")\n",
        "print(classification_report(y_test_eng, y_pred_selected))"
      ],
      "metadata": {
        "id": "wnYhNWkseOuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Compare model performance"
      ],
      "metadata": {
        "id": "Svw4DmaOeScM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Baseline Model Performance ---\")\n",
        "print(classification_report(y_test_base, y_pred_base))\n",
        "\n",
        "print(\"\\n--- Enhanced Model Performance (with Feature Engineering) ---\")\n",
        "print(classification_report(y_test_eng, y_pred_eng))\n",
        "\n",
        "print(\"\\n--- Model Performance (with Selected Features) ---\")\n",
        "print(classification_report(y_test_eng, y_pred_selected))\n",
        "\n",
        "# Summarize the performance metrics\n",
        "print(\"\\n--- Performance Summary ---\")\n",
        "print(\"Metric         | Baseline | Enhanced | Selected Features\")\n",
        "print(\"---------------|----------|----------|-------------------\")\n",
        "print(f\"Accuracy       | {accuracy_score(y_test_base, y_pred_base):<8.2f} | {accuracy_score(y_test_eng, y_pred_eng):<8.2f} | {accuracy_score(y_test_eng, y_pred_selected):<8.2f}\")\n",
        "\n",
        "# Extract F1-score for class 1 (Churn) from classification reports\n",
        "report_base = classification_report(y_test_base, y_pred_base, output_dict=True)\n",
        "report_eng = classification_report(y_test_eng, y_pred_eng, output_dict=True)\n",
        "report_selected = classification_report(y_test_eng, y_pred_selected, output_dict=True)\n",
        "\n",
        "f1_churn_base = report_base['1']['f1-score']\n",
        "f1_churn_eng = report_eng['1']['f1-score']\n",
        "f1_churn_selected = report_selected['1']['f1-score']\n",
        "\n",
        "print(f\"F1-Score (Churn)| {f1_churn_base:<8.2f} | {f1_churn_eng:<8.2f} | {f1_churn_selected:<8.2f}\")"
      ],
      "metadata": {
        "id": "jf-zAdZxeS_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}